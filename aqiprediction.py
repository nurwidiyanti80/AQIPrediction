# -*- coding: utf-8 -*-
"""AQIPrediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LbiBsYqgHY2QBuug7Zf9ZOLiF2zRfgNz
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# 1. Load dataset
df = pd.read_csv("jakarta_air_quality_range.csv")

# 2. Convert all columns (except datetime) to numeric
for col in df.columns:
    if col != 'datetime':
        df[col] = pd.to_numeric(df[col], errors='coerce')

# 3. Drop rows where all pollutant values are NaN
df = df.dropna(subset=[col for col in df.columns if col != 'datetime'], how='all')

# 4. Calculate correlation matrix
corr_matrix = df.drop(columns=['datetime']).corr()

# 5. Plot heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Matrix of Air Pollutants in Jakarta')
plt.tight_layout()
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# ✅ Load dataset using correct path
df = pd.read_csv('jakarta_air_quality_range.csv', parse_dates=['datetime'])

# Only select numeric columns for correlation
numeric_cols = ['pm2_5', 'pm10', 'no2', 'so2', 'co', 'o3']
correlation = df[numeric_cols].corr()

# Heatmap
plt.figure(figsize=(10, 6))
sns.heatmap(correlation, annot=True, cmap='coolwarm')
plt.title("Correlation Between Pollutants")
plt.show()

from xgboost import XGBRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
import numpy as np
import matplotlib.pyplot as plt

# Create lag feature
df['pm2_5_t-1'] = df['pm2_5'].shift(1)
df = df.dropna()

# Feature and target
X = df[['pm2_5_t-1']]
y = df['pm2_5']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=False, test_size=0.2)

# Train XGBoost model
xgb = XGBRegressor()
xgb.fit(X_train, y_train)

# Predict
y_pred_xgb = xgb.predict(X_test)

# RMSE
rmse_xgb = np.sqrt(mean_squared_error(y_test, y_pred_xgb))
print(f"XGBoost RMSE: {rmse_xgb:.2f}")

# --- Plot Actual vs Predicted ---
# Align time index
test_index = y_test.index

plt.figure(figsize=(12, 5))
plt.plot(test_index, y_test.values, label='Actual PM2.5', color='blue')
plt.plot(test_index, y_pred_xgb, label='XGBoost Prediction', color='orange')
plt.title('XGBoost Forecasting of PM2.5')
plt.xlabel('Date')
plt.ylabel('PM2.5')
plt.legend()
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
from xgboost import XGBRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt

# Load and prepare data
df = pd.read_csv("jakarta_air_quality_range.csv")
df.columns = df.columns.str.strip()

if 'datetime' in df.columns:
    df['datetime'] = pd.to_datetime(df['datetime'], errors='coerce')
    df = df.set_index('datetime')
    df = df.sort_index()
else:
    raise ValueError("No 'datetime' column found.")

# Rename column if needed for consistency
if 'PM2.5' in df.columns:
    df.rename(columns={'PM2.5': 'pm2_5'}, inplace=True)

# Create lag feature (t-1)
df['pm2_5_t-1'] = df['pm2_5'].shift(1)
df = df.dropna()

# Define features and target
X = df[['pm2_5_t-1']]
y = df['pm2_5']

# Train-test split without shuffling (important for time series)
X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=False, test_size=0.2)

# Train XGBoost model
xgb = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)
xgb.fit(X_train, y_train)

# Predict
y_pred_xgb = xgb.predict(X_test)

# Evaluate RMSE
rmse_xgb = np.sqrt(mean_squared_error(y_test, y_pred_xgb))
print(f"XGBoost RMSE: {rmse_xgb:.2f}")

# --- Plot prediction vs actual ---
plt.figure(figsize=(12, 5))
plt.plot(y_test.index, y_test, label='Actual PM2.5', color='blue')
plt.plot(y_test.index, y_pred_xgb, label='XGBoost Prediction', color='red')
plt.title('XGBoost Forecasting of PM2.5 with Lag Feature')
plt.xlabel('Date')
plt.ylabel('PM2.5')
plt.legend()
plt.tight_layout()
plt.show()

import pandas as pd
from statsmodels.tsa.arima.model import ARIMA
from sklearn.metrics import mean_squared_error
import numpy as np
import matplotlib.pyplot as plt

# --- Load and prepare data (already done) ---
df = pd.read_csv("jakarta_air_quality_range.csv")
df.columns = df.columns.str.strip()

if 'datetime' in df.columns:
    df['datetime'] = pd.to_datetime(df['datetime'], errors='coerce')
    df = df.set_index('datetime')
    df = df.sort_index()
else:
    raise ValueError("No 'datetime' column found.")

# --- Choose target column ---
target_col = 'pm2_5'

# Drop missing values in the target column
ts = df[target_col].dropna()

# --- Split into train and test ---
split_ratio = 0.8
split_point = int(len(ts) * split_ratio)
train, test = ts[:split_point], ts[split_point:]

# --- Fit ARIMA model ---
model = ARIMA(train, order=(5, 1, 0))  # (p,d,q) — adjust as needed
model_fit = model.fit()

# --- Forecast ---
forecast = model_fit.forecast(steps=len(test))

# --- Evaluate ---
rmse = np.sqrt(mean_squared_error(test, forecast))
print(f"ARIMA RMSE: {rmse:.2f}")

# --- Plot ---
plt.figure(figsize=(12, 5))
plt.plot(train.index, train, label='Train')
plt.plot(test.index, test, label='Test', color='orange')
plt.plot(test.index, forecast, label='Forecast', color='green')
plt.title(f'ARIMA Forecasting for {target_col}')
plt.xlabel('Date')
plt.ylabel(target_col)
plt.legend()
plt.tight_layout()
plt.show()

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error

# Load and preprocess
df = pd.read_csv("jakarta_air_quality_range.csv")
df.columns = df.columns.str.strip()

if 'datetime' in df.columns:
    df['datetime'] = pd.to_datetime(df['datetime'], errors='coerce')
    df = df.set_index('datetime')
    df = df.sort_index()
else:
    raise ValueError("No 'datetime' column found.")

# Rename column if needed
if 'PM2.5' in df.columns:
    df.rename(columns={'PM2.5': 'pm2_5'}, inplace=True)

# Scale data
scaler = MinMaxScaler()
scaled_data = scaler.fit_transform(df[['pm2_5']])

# Create sequences
def create_sequences(data, seq_length):
    X, y = [], []
    for i in range(len(data) - seq_length):
        X.append(data[i:i + seq_length])
        y.append(data[i + seq_length])
    return np.array(X), np.array(y)

seq_length = 5
X_lstm, y_lstm = create_sequences(scaled_data, seq_length)

# Train/test split
split = int(len(X_lstm) * 0.8)
X_train_lstm, X_test_lstm = X_lstm[:split], X_lstm[split:]
y_train_lstm, y_test_lstm = y_lstm[:split], y_lstm[split:]

# Reshape for LSTM input
X_train_lstm = X_train_lstm.reshape((X_train_lstm.shape[0], X_train_lstm.shape[1], 1))
X_test_lstm = X_test_lstm.reshape((X_test_lstm.shape[0], X_test_lstm.shape[1], 1))

# Build and train model
model = Sequential()
model.add(LSTM(50, activation='relu', input_shape=(seq_length, 1)))
model.add(Dense(1))
model.compile(optimizer='adam', loss='mse')
model.fit(X_train_lstm, y_train_lstm, epochs=10, batch_size=16, verbose=0)

# Predict
y_pred_lstm = model.predict(X_test_lstm)

# Inverse transform
y_pred_lstm_inv = scaler.inverse_transform(y_pred_lstm)
y_test_lstm_inv = scaler.inverse_transform(y_test_lstm)

# Calculate RMSE
rmse_lstm = np.sqrt(mean_squared_error(y_test_lstm_inv, y_pred_lstm_inv))
print(f"LSTM RMSE: {rmse_lstm:.2f}")

# --- Plot actual vs predicted ---
# Align the time index
test_dates = df.index[seq_length + split: seq_length + split + len(y_test_lstm)]

plt.figure(figsize=(12, 5))
plt.plot(test_dates, y_test_lstm_inv, label='Actual PM2.5', color='blue')
plt.plot(test_dates, y_pred_lstm_inv, label='LSTM Prediction', color='green')
plt.title('LSTM Forecasting of PM2.5')
plt.xlabel('Date')
plt.ylabel('PM2.5')
plt.legend()
plt.tight_layout()
plt.show()

print("Model Performance (RMSE):")
print(f"XGBoost: {rmse_xgb:.2f}")
print(f"ARIMA:   {rmse_arima:.2f}")
print(f"LSTM:    {rmse_lstm:.2f}")

import pandas as pd
import numpy as np
from xgboost import XGBRegressor
import matplotlib.pyplot as plt

# 1. Load data
df = pd.read_csv("jakarta_air_quality_range.csv")
df['date'] = pd.to_datetime(df['datetime'])
df = df.sort_values('date')

# 2. Buat fitur lag-1
df['pm2_5_t-1'] = df['pm2_5'].shift(1)
df = df.dropna()

# 3. Gunakan data sampai 25 Juni 2025
cutoff_date = pd.to_datetime("2025-06-25")
train_df = df[df['date'] <= cutoff_date].copy()

# 4. Latih model XGBoost
X_train = train_df[['pm2_5_t-1']]
y_train = train_df['pm2_5']
model = XGBRegressor()
model.fit(X_train, y_train)

# 5. Prediksi 26 Juni – 31 Juli (36 hari)
last_pm = train_df.iloc[-1]['pm2_5']
predictions = []
dates = pd.date_range(start="2025-06-26", periods=36)

for _ in range(36):
    next_pred = model.predict(np.array([[last_pm]]))[0]
    predictions.append(next_pred)
    last_pm = next_pred

# 6. Hasil dan visualisasi
forecast_df = pd.DataFrame({'date': dates, 'predicted_pm2_5': predictions})

plt.figure(figsize=(12, 6))
plt.plot(df['date'], df['pm2_5'], label='Historical PM2.5', alpha=0.6)
plt.plot(forecast_df['date'], forecast_df['predicted_pm2_5'], label='Forecast PM2.5', color='red', marker='o')
plt.title("PM2.5 Prediction for Jakarta (26 June - 31 July 2025)")
plt.xlabel("Date")
plt.ylabel("PM2.5 Concentration (µg/m³)")
plt.legend()
plt.grid(True)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

print(forecast_df)